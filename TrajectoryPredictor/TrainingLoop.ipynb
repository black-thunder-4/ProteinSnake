{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3978c77-de08-49d2-b837-fb25df738098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0, device_ids=[0]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from ProteinTrajectoryDataset import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from Models import *\n",
    "\n",
    "device_ids = [0]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device {device}, device_ids={device_ids}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "MAX_PROTEIN_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165ace2f-b481-4e59-934c-34e144688659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0, device_ids=[0]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading trajectories: 100%|████████████████████████████████████████████████████████████| 80/80 [03:08<00:00,  2.35s/it]\n",
      "Loading trajectories: 100%|████████████████████████████████████████████████████████████| 20/20 [00:41<00:00,  2.05s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collate_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m ProteinTrajectoryDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_trajectories\u001b[39m\u001b[38;5;124m'\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m overfitting_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubset(train_dataset, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)))\n\u001b[1;32m---> 24\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39m\u001b[43mcollate_fn\u001b[49m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(batch):\n\u001b[0;32m     27\u001b[0m     coords \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'collate_fn' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = ProteinTrajectoryDataset('train_trajectories', n_steps=1)\n",
    "val_dataset = ProteinTrajectoryDataset('val_trajectories', n_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51939ed-6aa2-4e34-906f-68e9778ece33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    coords = [item['coords'] for item in batch]\n",
    "    residues = [item['residues'] for item in batch]\n",
    "    deltas = [item['delta'] for item in batch]\n",
    "    lengths = torch.tensor([c.shape[0] for c in coords])\n",
    "    # Pad sequences to the maximum length in the batch (batch_first=True gives shape [batch, max_length, features])\n",
    "    coords = pad_sequence(coords, batch_first=True)\n",
    "    residues = pad_sequence(residues, batch_first=True)\n",
    "    deltas = pad_sequence(deltas, batch_first=True)\n",
    "    return coords, residues, deltas, lengths\n",
    "\n",
    "def masked_mse_loss(pred, target, lengths):\n",
    "    batch_size, max_length, _ = pred.shape\n",
    "    # Create a mask with shape (batch_size, max_length) where each element is True if it is a valid timestep.\n",
    "    mask = torch.arange(max_length, device=pred.device).expand(batch_size, max_length) < lengths.unsqueeze(1)\n",
    "    # Expand mask to match the last dimension (3) of our tensors.\n",
    "    mask = mask.unsqueeze(2).float()  # shape becomes (batch_size, max_length, 1)\n",
    "    \n",
    "    # Compute squared differences\n",
    "    mse = (pred - target) ** 2\n",
    "    # Zero-out padded elements using the mask and compute average loss only over valid elements.\n",
    "    loss = (mse * mask).sum() / mask.sum()\n",
    "    return loss\n",
    "\n",
    "def train_model(model, dataloader, optimizer, num_epochs=10):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for coords, residues, deltas, lengths in pbar:\n",
    "            \n",
    "            # Move data to device\n",
    "            coords = coords.to(device)\n",
    "            residues = residues.to(device)\n",
    "            deltas = deltas.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass: predict deltas using currents.\n",
    "            pred_deltas = model(coords, residues, lengths)\n",
    "            \n",
    "            # Compute the masked MSE loss.\n",
    "            loss = masked_mse_loss(pred_deltas, deltas, lengths)\n",
    "            \n",
    "            # Backward pass and optimization.\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update running loss.\n",
    "            batch_size = coords.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            \n",
    "            avg_loss = running_loss / total_samples\n",
    "            pbar.set_postfix(avg_loss=avg_loss, current_loss=loss.item())\n",
    "        \n",
    "        # Print epoch loss summary.\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {epoch_loss:.5f}\")\n",
    "\n",
    "def eval_model(model, dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Evaluating\")\n",
    "    for coords, residues, deltas, lengths in pbar:\n",
    "        \n",
    "        # Move data to device\n",
    "        coords = coords.to(device)\n",
    "        residues = residues.to(device)\n",
    "        deltas = deltas.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        # Forward pass: predict deltas using currents.\n",
    "        pred_deltas = model(coords, residues, lengths)\n",
    "        \n",
    "        # Compute the masked MSE loss.\n",
    "        loss = masked_mse_loss(pred_deltas, deltas, lengths)\n",
    "        \n",
    "        # Update running loss.\n",
    "        batch_size = coords.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        avg_loss = running_loss / total_samples\n",
    "        pbar.set_postfix(avg_loss=avg_loss, current_loss=loss.item())\n",
    "    \n",
    "    # Print epoch loss summary.\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    print(f\"Evaluating - Average Loss: {epoch_loss:.5f}\")\n",
    "\n",
    "def cnn_objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256, 512, 1024])\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    # Build model\n",
    "    model = CNN_Model(\n",
    "        channels_1=trial.suggest_categorical('channels_1', [4, 8, 16, 32, 64, 128]),\n",
    "        channels_2=trial.suggest_categorical('channels_2', [4, 8, 16, 32, 64, 128]),\n",
    "        kernel_size_1=trial.suggest_categorical('kernel_size_1', [1, 3, 5, 7]),\n",
    "        kernel_size_2=trial.suggest_categorical('kernel_size_2', [1, 3, 5, 7]),\n",
    "        kernel_size_3=trial.suggest_categorical('kernel_size_3', [1, 3, 5, 7]),\n",
    "    )\n",
    "    \n",
    "    # Wrap with DataParallel if multiple GPUs are specified\n",
    "    if len(device_ids) > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Choose optimizer\n",
    "    params = model.parameters()\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(params, lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
    "\n",
    "    coordinate_factor = trial.suggest_float('coordinate_factor', 0.1, 10, log=True)\n",
    "\n",
    "    # Training loop\n",
    "    max_epochs = 100  # Set a reasonable upper limit to avoid infinite loops\n",
    "    epoch = 0\n",
    "    while epoch < max_epochs:\n",
    "        model.train()\n",
    "        for coords, residues, deltas, lengths in tqdm.tqdm(train_loader):\n",
    "            coords = coords.to(device) * coordinate_factor\n",
    "            residues = residues.to(device)\n",
    "            deltas = deltas.to(device) * coordinate_factor\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_deltas = model(coords, residues, lengths)\n",
    "            loss = masked_mse_loss(pred_deltas, deltas, lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Intermediate evaluation\n",
    "        running_loss = 0\n",
    "        total_samples = 0\n",
    "        model.eval()\n",
    "        for coords, residues, deltas, lengths in tqdm.tqdm(val_loader):\n",
    "            coords = coords.to(device) * coordinate_factor\n",
    "            residues = residues.to(device)\n",
    "            deltas = deltas.to(device) * coordinate_factor\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            pred_deltas = model(coords, residues, lengths)\n",
    "            loss = masked_mse_loss(pred_deltas, deltas, lengths)\n",
    "\n",
    "            batch_size = coords.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "        \n",
    "        val_loss = running_loss / total_samples / (coordinate_factor ** 2)\n",
    "        trial.report(val_loss, epoch)\n",
    "\n",
    "        # Optuna pruning\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9022f41-ad29-475a-87a7-2f877eeb7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "283a3346-80d2-4f44-aabe-5793ade7a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import *\n",
    "\n",
    "#model = CNN_Model().to(device)\n",
    "model = EGNN_Model(MAX_PROTEIN_LENGTH, depth=1, emb_dim=8).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca593214-81e8-480a-a9ac-c350db5c7984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:  87%|██████████████████████▌   | 271/313 [01:13<00:11,  3.70it/s, avg_loss=0.00266, current_loss=0.00245]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Forward pass: predict deltas using currents.\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m pred_deltas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Compute the masked MSE loss.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m masked_mse_loss(pred_deltas, deltas, lengths)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\JKU\\Thesis\\TrajectoryPredictor\\Models.py:109\u001b[0m, in \u001b[0;36mEGNN_Model.forward\u001b[1;34m(self, coords, residues, lengths)\u001b[0m\n\u001b[0;32m    106\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(L, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(B, L) \u001b[38;5;241m<\u001b[39m lengths\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Create adjacency matrix for chain connectivity (all samples are padded to max length L).\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m adj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_chain_adj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Pass through EGNN_Network.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Here we assume that the EGNN_Network's forward method accepts keyword arguments:\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m#   - coords: the node coordinates,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m#   - adj: the adjacency matrix.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# It returns the predicted delta for each node.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m feats_out, coords_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39megnn(residues, coords, mask\u001b[38;5;241m=\u001b[39mmask, adj_mat\u001b[38;5;241m=\u001b[39madj)\n",
      "File \u001b[1;32m~\\Documents\\JKU\\Thesis\\TrajectoryPredictor\\Models.py:85\u001b[0m, in \u001b[0;36mEGNN_Model.create_chain_adj\u001b[1;34m(self, lengths, max_length)\u001b[0m\n\u001b[0;32m     83\u001b[0m L \u001b[38;5;241m=\u001b[39m lengths[b]\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m L \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 85\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Connect residue i with i+1.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     adj[b, idx, idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, optimizer, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67ae5a-bce8-49ba-843e-74c6d0d6bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d261b5c4-cd04-4415-88af-f1ecec3d162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                                                              | 0/399 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|                                          | 0/399 [00:00<?, ?it/s, avg_loss=0.271, current_loss=0.271]\u001b[A\n",
      "Evaluating:   0%|                                          | 0/399 [00:00<?, ?it/s, avg_loss=0.268, current_loss=0.265]\u001b[A\n",
      "Evaluating:   0%|                                           | 0/399 [00:00<?, ?it/s, avg_loss=0.26, current_loss=0.242]\u001b[A\n",
      "Evaluating:   0%|                                          | 0/399 [00:00<?, ?it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:   1%|▎                                 | 4/399 [00:00<00:10, 37.58it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:   1%|▎                                  | 4/399 [00:00<00:10, 37.58it/s, avg_loss=0.264, current_loss=0.27]\u001b[A\n",
      "Evaluating:   1%|▎                                 | 4/399 [00:00<00:10, 37.58it/s, avg_loss=0.265, current_loss=0.266]\u001b[A\n",
      "Evaluating:   1%|▎                                 | 4/399 [00:00<00:10, 37.58it/s, avg_loss=0.262, current_loss=0.247]\u001b[A\n",
      "Evaluating:   1%|▎                                  | 4/399 [00:00<00:10, 37.58it/s, avg_loss=0.26, current_loss=0.245]\u001b[A\n",
      "Evaluating:   2%|▋                                  | 8/399 [00:00<00:13, 30.05it/s, avg_loss=0.26, current_loss=0.245]\u001b[A\n",
      "Evaluating:   2%|▋                                 | 8/399 [00:00<00:13, 30.05it/s, avg_loss=0.263, current_loss=0.285]\u001b[A\n",
      "Evaluating:   2%|▋                                 | 8/399 [00:00<00:13, 30.05it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:   2%|▋                                  | 8/399 [00:00<00:13, 30.05it/s, avg_loss=0.264, current_loss=0.28]\u001b[A\n",
      "Evaluating:   2%|▋                                 | 8/399 [00:00<00:13, 30.05it/s, avg_loss=0.264, current_loss=0.264]\u001b[A\n",
      "Evaluating:   3%|▉                                | 12/399 [00:00<00:11, 33.54it/s, avg_loss=0.264, current_loss=0.264]\u001b[A\n",
      "Evaluating:   3%|▉                                | 12/399 [00:00<00:11, 33.54it/s, avg_loss=0.265, current_loss=0.266]\u001b[A\n",
      "Evaluating:   3%|▉                                | 12/399 [00:00<00:11, 33.54it/s, avg_loss=0.265, current_loss=0.266]\u001b[A\n",
      "Evaluating:   3%|▉                                | 12/399 [00:00<00:11, 33.54it/s, avg_loss=0.264, current_loss=0.254]\u001b[A\n",
      "Evaluating:   3%|▉                                | 12/399 [00:00<00:11, 33.54it/s, avg_loss=0.265, current_loss=0.273]\u001b[A\n",
      "Evaluating:   4%|█▎                               | 16/399 [00:00<00:12, 29.77it/s, avg_loss=0.265, current_loss=0.273]\u001b[A\n",
      "Evaluating:   4%|█▎                               | 16/399 [00:00<00:12, 29.77it/s, avg_loss=0.264, current_loss=0.259]\u001b[A\n",
      "Evaluating:   4%|█▎                               | 16/399 [00:00<00:12, 29.77it/s, avg_loss=0.264, current_loss=0.262]\u001b[A\n",
      "Evaluating:   4%|█▎                               | 16/399 [00:00<00:12, 29.77it/s, avg_loss=0.264, current_loss=0.264]\u001b[A\n",
      "Evaluating:   4%|█▎                               | 16/399 [00:00<00:12, 29.77it/s, avg_loss=0.265, current_loss=0.276]\u001b[A\n",
      "Evaluating:   5%|█▋                               | 20/399 [00:00<00:11, 32.14it/s, avg_loss=0.265, current_loss=0.276]\u001b[A\n",
      "Evaluating:   5%|█▋                               | 20/399 [00:00<00:11, 32.14it/s, avg_loss=0.265, current_loss=0.273]\u001b[A\n",
      "Evaluating:   5%|█▋                               | 20/399 [00:00<00:11, 32.14it/s, avg_loss=0.264, current_loss=0.238]\u001b[A\n",
      "Evaluating:   5%|█▋                               | 20/399 [00:00<00:11, 32.14it/s, avg_loss=0.265, current_loss=0.279]\u001b[A\n",
      "Evaluating:   5%|█▋                               | 20/399 [00:00<00:11, 32.14it/s, avg_loss=0.264, current_loss=0.255]\u001b[A\n",
      "Evaluating:   6%|█▉                               | 24/399 [00:00<00:12, 29.75it/s, avg_loss=0.264, current_loss=0.255]\u001b[A\n",
      "Evaluating:   6%|█▉                               | 24/399 [00:00<00:12, 29.75it/s, avg_loss=0.264, current_loss=0.253]\u001b[A\n",
      "Evaluating:   6%|██                                | 24/399 [00:00<00:12, 29.75it/s, avg_loss=0.264, current_loss=0.27]\u001b[A\n",
      "Evaluating:   6%|█▉                               | 24/399 [00:00<00:12, 29.75it/s, avg_loss=0.264, current_loss=0.258]\u001b[A\n",
      "Evaluating:   6%|█▉                               | 24/399 [00:00<00:12, 29.75it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:   7%|██▎                              | 28/399 [00:00<00:12, 28.59it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:   7%|██▎                              | 28/399 [00:00<00:12, 28.59it/s, avg_loss=0.264, current_loss=0.268]\u001b[A\n",
      "Evaluating:   7%|██▎                              | 28/399 [00:00<00:12, 28.59it/s, avg_loss=0.263, current_loss=0.252]\u001b[A\n",
      "Evaluating:   7%|██▎                              | 28/399 [00:01<00:12, 28.59it/s, avg_loss=0.264, current_loss=0.277]\u001b[A\n",
      "Evaluating:   7%|██▎                              | 28/399 [00:01<00:12, 28.59it/s, avg_loss=0.264, current_loss=0.269]\u001b[A\n",
      "Evaluating:   8%|██▋                              | 32/399 [00:01<00:11, 31.10it/s, avg_loss=0.264, current_loss=0.269]\u001b[A\n",
      "Evaluating:   8%|██▋                              | 32/399 [00:01<00:11, 31.10it/s, avg_loss=0.264, current_loss=0.267]\u001b[A\n",
      "Evaluating:   8%|██▋                              | 32/399 [00:01<00:11, 31.10it/s, avg_loss=0.264, current_loss=0.267]\u001b[A\n",
      "Evaluating:   8%|██▋                              | 32/399 [00:01<00:11, 31.10it/s, avg_loss=0.264, current_loss=0.264]\u001b[A\n",
      "Evaluating:   8%|██▋                              | 32/399 [00:01<00:11, 31.10it/s, avg_loss=0.264, current_loss=0.271]\u001b[A\n",
      "Evaluating:   9%|██▉                              | 36/399 [00:01<00:11, 32.83it/s, avg_loss=0.264, current_loss=0.271]\u001b[A\n",
      "Evaluating:   9%|██▉                              | 36/399 [00:01<00:11, 32.83it/s, avg_loss=0.264, current_loss=0.264]\u001b[A\n",
      "Evaluating:   9%|██▉                              | 36/399 [00:01<00:11, 32.83it/s, avg_loss=0.263, current_loss=0.236]\u001b[A\n",
      "Evaluating:   9%|██▉                              | 36/399 [00:01<00:11, 32.83it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:   9%|██▉                              | 36/399 [00:01<00:11, 32.83it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  10%|███▎                             | 40/399 [00:01<00:10, 34.46it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  10%|███▎                             | 40/399 [00:01<00:10, 34.46it/s, avg_loss=0.263, current_loss=0.275]\u001b[A\n",
      "Evaluating:  10%|███▎                             | 40/399 [00:01<00:10, 34.46it/s, avg_loss=0.263, current_loss=0.257]\u001b[A\n",
      "Evaluating:  10%|███▎                             | 40/399 [00:01<00:10, 34.46it/s, avg_loss=0.263, current_loss=0.269]\u001b[A\n",
      "Evaluating:  10%|███▎                             | 40/399 [00:01<00:10, 34.46it/s, avg_loss=0.263, current_loss=0.252]\u001b[A\n",
      "Evaluating:  11%|███▋                             | 44/399 [00:01<00:11, 32.27it/s, avg_loss=0.263, current_loss=0.252]\u001b[A\n",
      "Evaluating:  11%|███▋                             | 44/399 [00:01<00:11, 32.27it/s, avg_loss=0.263, current_loss=0.248]\u001b[A\n",
      "Evaluating:  11%|███▋                             | 44/399 [00:01<00:11, 32.27it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  11%|███▋                             | 44/399 [00:01<00:11, 32.27it/s, avg_loss=0.263, current_loss=0.269]\u001b[A\n",
      "Evaluating:  11%|███▋                             | 44/399 [00:01<00:11, 32.27it/s, avg_loss=0.263, current_loss=0.259]\u001b[A\n",
      "Evaluating:  12%|███▉                             | 48/399 [00:01<00:10, 33.87it/s, avg_loss=0.263, current_loss=0.259]\u001b[A\n",
      "Evaluating:  12%|████                              | 48/399 [00:01<00:10, 33.87it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  12%|███▉                             | 48/399 [00:01<00:10, 33.87it/s, avg_loss=0.263, current_loss=0.263]\u001b[A\n",
      "Evaluating:  12%|███▉                             | 48/399 [00:01<00:10, 33.87it/s, avg_loss=0.263, current_loss=0.264]\u001b[A\n",
      "Evaluating:  12%|████                              | 48/399 [00:01<00:10, 33.87it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  13%|████▍                             | 52/399 [00:01<00:10, 34.61it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  13%|████▎                            | 52/399 [00:01<00:10, 34.61it/s, avg_loss=0.263, current_loss=0.264]\u001b[A\n",
      "Evaluating:  13%|████▎                            | 52/399 [00:01<00:10, 34.61it/s, avg_loss=0.263, current_loss=0.273]\u001b[A\n",
      "Evaluating:  13%|████▎                            | 52/399 [00:01<00:10, 34.61it/s, avg_loss=0.263, current_loss=0.251]\u001b[A\n",
      "Evaluating:  13%|████▎                            | 52/399 [00:01<00:10, 34.61it/s, avg_loss=0.262, current_loss=0.246]\u001b[A\n",
      "Evaluating:  13%|████▎                            | 52/399 [00:01<00:10, 34.61it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  14%|████▋                            | 57/399 [00:01<00:09, 36.99it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  14%|████▋                            | 57/399 [00:01<00:09, 36.99it/s, avg_loss=0.262, current_loss=0.262]\u001b[A\n",
      "Evaluating:  14%|████▋                            | 57/399 [00:01<00:09, 36.99it/s, avg_loss=0.262, current_loss=0.253]\u001b[A\n",
      "Evaluating:  14%|████▋                            | 57/399 [00:01<00:09, 36.99it/s, avg_loss=0.262, current_loss=0.274]\u001b[A\n",
      "Evaluating:  14%|████▋                            | 57/399 [00:01<00:09, 36.99it/s, avg_loss=0.262, current_loss=0.258]\u001b[A\n",
      "Evaluating:  15%|█████                            | 61/399 [00:01<00:09, 37.11it/s, avg_loss=0.262, current_loss=0.258]\u001b[A\n",
      "Evaluating:  15%|█████                            | 61/399 [00:01<00:09, 37.11it/s, avg_loss=0.262, current_loss=0.247]\u001b[A\n",
      "Evaluating:  15%|█████                            | 61/399 [00:01<00:09, 37.11it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  15%|█████                            | 61/399 [00:01<00:09, 37.11it/s, avg_loss=0.262, current_loss=0.234]\u001b[A\n",
      "Evaluating:  15%|█████▏                            | 61/399 [00:01<00:09, 37.11it/s, avg_loss=0.262, current_loss=0.26]\u001b[A\n",
      "Evaluating:  16%|█████▌                            | 65/399 [00:01<00:08, 37.89it/s, avg_loss=0.262, current_loss=0.26]\u001b[A\n",
      "Evaluating:  16%|█████▍                           | 65/399 [00:01<00:08, 37.89it/s, avg_loss=0.262, current_loss=0.255]\u001b[A\n",
      "Evaluating:  16%|█████▍                           | 65/399 [00:01<00:08, 37.89it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  16%|█████▍                           | 65/399 [00:02<00:08, 37.89it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  16%|█████▍                           | 65/399 [00:02<00:08, 37.89it/s, avg_loss=0.262, current_loss=0.275]\u001b[A\n",
      "Evaluating:  17%|█████▋                           | 69/399 [00:02<00:08, 37.46it/s, avg_loss=0.262, current_loss=0.275]\u001b[A\n",
      "Evaluating:  17%|█████▋                           | 69/399 [00:02<00:08, 37.46it/s, avg_loss=0.262, current_loss=0.255]\u001b[A\n",
      "Evaluating:  17%|█████▋                           | 69/399 [00:02<00:08, 37.46it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  17%|█████▋                           | 69/399 [00:02<00:08, 37.46it/s, avg_loss=0.261, current_loss=0.265]\u001b[A\n",
      "Evaluating:  17%|█████▋                           | 69/399 [00:02<00:08, 37.46it/s, avg_loss=0.262, current_loss=0.266]\u001b[A\n",
      "Evaluating:  18%|██████                           | 73/399 [00:02<00:08, 37.34it/s, avg_loss=0.262, current_loss=0.266]\u001b[A\n",
      "Evaluating:  18%|██████                           | 73/399 [00:02<00:08, 37.34it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  18%|██████                           | 73/399 [00:02<00:08, 37.34it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  18%|██████▏                           | 73/399 [00:02<00:08, 37.34it/s, avg_loss=0.261, current_loss=0.26]\u001b[A\n",
      "Evaluating:  18%|██████                           | 73/399 [00:02<00:08, 37.34it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  19%|██████▎                          | 77/399 [00:02<00:08, 37.87it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  19%|██████▎                          | 77/399 [00:02<00:08, 37.87it/s, avg_loss=0.261, current_loss=0.267]\u001b[A\n",
      "Evaluating:  19%|██████▎                          | 77/399 [00:02<00:08, 37.87it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  19%|██████▎                          | 77/399 [00:02<00:08, 37.87it/s, avg_loss=0.261, current_loss=0.269]\u001b[A\n",
      "Evaluating:  19%|██████▎                          | 77/399 [00:02<00:08, 37.87it/s, avg_loss=0.262, current_loss=0.268]\u001b[A\n",
      "Evaluating:  20%|██████▋                          | 81/399 [00:02<00:08, 37.92it/s, avg_loss=0.262, current_loss=0.268]\u001b[A\n",
      "Evaluating:  20%|██████▋                          | 81/399 [00:02<00:08, 37.92it/s, avg_loss=0.262, current_loss=0.269]\u001b[A\n",
      "Evaluating:  20%|██████▉                           | 81/399 [00:02<00:08, 37.92it/s, avg_loss=0.262, current_loss=0.29]\u001b[A\n",
      "Evaluating:  20%|██████▋                          | 81/399 [00:02<00:08, 37.92it/s, avg_loss=0.262, current_loss=0.274]\u001b[A\n",
      "Evaluating:  20%|██████▋                          | 81/399 [00:02<00:08, 37.92it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  21%|███████                          | 85/399 [00:02<00:09, 33.73it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  21%|███████                          | 85/399 [00:02<00:09, 33.73it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  21%|███████                          | 85/399 [00:02<00:09, 33.73it/s, avg_loss=0.262, current_loss=0.269]\u001b[A\n",
      "Evaluating:  21%|███████▏                          | 85/399 [00:02<00:09, 33.73it/s, avg_loss=0.262, current_loss=0.26]\u001b[A\n",
      "Evaluating:  21%|███████                          | 85/399 [00:02<00:09, 33.73it/s, avg_loss=0.262, current_loss=0.244]\u001b[A\n",
      "Evaluating:  21%|███████                          | 85/399 [00:02<00:09, 33.73it/s, avg_loss=0.262, current_loss=0.251]\u001b[A\n",
      "Evaluating:  23%|███████▍                         | 90/399 [00:02<00:08, 35.36it/s, avg_loss=0.262, current_loss=0.251]\u001b[A\n",
      "Evaluating:  23%|███████▋                          | 90/399 [00:02<00:08, 35.36it/s, avg_loss=0.262, current_loss=0.25]\u001b[A\n",
      "Evaluating:  23%|███████▍                         | 90/399 [00:02<00:08, 35.36it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  23%|███████▍                         | 90/399 [00:02<00:08, 35.36it/s, avg_loss=0.262, current_loss=0.259]\u001b[A\n",
      "Evaluating:  23%|███████▍                         | 90/399 [00:02<00:08, 35.36it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  24%|███████▊                         | 94/399 [00:02<00:08, 35.39it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  24%|███████▊                         | 94/399 [00:02<00:08, 35.39it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  24%|███████▊                         | 94/399 [00:02<00:08, 35.39it/s, avg_loss=0.261, current_loss=0.242]\u001b[A\n",
      "Evaluating:  24%|███████▊                         | 94/399 [00:02<00:08, 35.39it/s, avg_loss=0.261, current_loss=0.257]\u001b[A\n",
      "Evaluating:  24%|███████▊                         | 94/399 [00:02<00:08, 35.39it/s, avg_loss=0.261, current_loss=0.262]\u001b[A\n",
      "Evaluating:  25%|████████                         | 98/399 [00:02<00:08, 34.13it/s, avg_loss=0.261, current_loss=0.262]\u001b[A\n",
      "Evaluating:  25%|████████                         | 98/399 [00:02<00:08, 34.13it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  25%|████████                         | 98/399 [00:02<00:08, 34.13it/s, avg_loss=0.261, current_loss=0.272]\u001b[A\n",
      "Evaluating:  25%|████████                         | 98/399 [00:02<00:08, 34.13it/s, avg_loss=0.261, current_loss=0.262]\u001b[A\n",
      "Evaluating:  25%|████████                         | 98/399 [00:02<00:08, 34.13it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  26%|████████▏                       | 102/399 [00:02<00:08, 34.69it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  26%|████████▏                       | 102/399 [00:03<00:08, 34.69it/s, avg_loss=0.262, current_loss=0.284]\u001b[A\n",
      "Evaluating:  26%|████████▏                       | 102/399 [00:03<00:08, 34.69it/s, avg_loss=0.262, current_loss=0.272]\u001b[A\n",
      "Evaluating:  26%|████████▏                       | 102/399 [00:03<00:08, 34.69it/s, avg_loss=0.262, current_loss=0.251]\u001b[A\n",
      "Evaluating:  26%|████████▏                       | 102/399 [00:03<00:08, 34.69it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  27%|████████▌                       | 106/399 [00:03<00:08, 35.82it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  27%|████████▌                       | 106/399 [00:03<00:08, 35.82it/s, avg_loss=0.262, current_loss=0.273]\u001b[A\n",
      "Evaluating:  27%|████████▌                       | 106/399 [00:03<00:08, 35.82it/s, avg_loss=0.262, current_loss=0.258]\u001b[A\n",
      "Evaluating:  27%|████████▊                        | 106/399 [00:03<00:08, 35.82it/s, avg_loss=0.262, current_loss=0.26]\u001b[A\n",
      "Evaluating:  27%|████████▌                       | 106/399 [00:03<00:08, 35.82it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  28%|████████▊                       | 110/399 [00:03<00:08, 34.12it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  28%|████████▊                       | 110/399 [00:03<00:08, 34.12it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  28%|████████▊                       | 110/399 [00:03<00:08, 34.12it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  28%|████████▊                       | 110/399 [00:03<00:08, 34.12it/s, avg_loss=0.261, current_loss=0.273]\u001b[A\n",
      "Evaluating:  28%|████████▊                       | 110/399 [00:03<00:08, 34.12it/s, avg_loss=0.261, current_loss=0.261]\u001b[A\n",
      "Evaluating:  29%|█████████▏                      | 114/399 [00:03<00:08, 33.22it/s, avg_loss=0.261, current_loss=0.261]\u001b[A\n",
      "Evaluating:  29%|█████████▏                      | 114/399 [00:03<00:08, 33.22it/s, avg_loss=0.261, current_loss=0.256]\u001b[A\n",
      "Evaluating:  29%|█████████▏                      | 114/399 [00:03<00:08, 33.22it/s, avg_loss=0.261, current_loss=0.246]\u001b[A\n",
      "Evaluating:  29%|█████████▏                      | 114/399 [00:03<00:08, 33.22it/s, avg_loss=0.261, current_loss=0.282]\u001b[A\n",
      "Evaluating:  29%|█████████▏                      | 114/399 [00:03<00:08, 33.22it/s, avg_loss=0.261, current_loss=0.253]\u001b[A\n",
      "Evaluating:  30%|█████████▍                      | 118/399 [00:03<00:09, 30.12it/s, avg_loss=0.261, current_loss=0.253]\u001b[A\n",
      "Evaluating:  30%|█████████▍                      | 118/399 [00:03<00:09, 30.12it/s, avg_loss=0.261, current_loss=0.257]\u001b[A\n",
      "Evaluating:  30%|█████████▊                       | 118/399 [00:03<00:09, 30.12it/s, avg_loss=0.261, current_loss=0.25]\u001b[A\n",
      "Evaluating:  30%|█████████▍                      | 118/399 [00:03<00:09, 30.12it/s, avg_loss=0.261, current_loss=0.235]\u001b[A\n",
      "Evaluating:  30%|█████████▍                      | 118/399 [00:03<00:09, 30.12it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  31%|█████████▊                      | 122/399 [00:03<00:08, 32.06it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  31%|█████████▊                      | 122/399 [00:03<00:08, 32.06it/s, avg_loss=0.261, current_loss=0.275]\u001b[A\n",
      "Evaluating:  31%|█████████▊                      | 122/399 [00:03<00:08, 32.06it/s, avg_loss=0.261, current_loss=0.274]\u001b[A\n",
      "Evaluating:  31%|█████████▊                      | 122/399 [00:03<00:08, 32.06it/s, avg_loss=0.261, current_loss=0.274]\u001b[A\n",
      "Evaluating:  31%|█████████▊                      | 122/399 [00:03<00:08, 32.06it/s, avg_loss=0.261, current_loss=0.273]\u001b[A\n",
      "Evaluating:  31%|█████████▊                      | 122/399 [00:03<00:08, 32.06it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  32%|██████████▏                     | 127/399 [00:03<00:07, 34.50it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  32%|██████████▏                     | 127/399 [00:03<00:07, 34.50it/s, avg_loss=0.261, current_loss=0.255]\u001b[A\n",
      "Evaluating:  32%|██████████▏                     | 127/399 [00:03<00:07, 34.50it/s, avg_loss=0.261, current_loss=0.249]\u001b[A\n",
      "Evaluating:  32%|██████████▏                     | 127/399 [00:03<00:07, 34.50it/s, avg_loss=0.261, current_loss=0.271]\u001b[A\n",
      "Evaluating:  32%|██████████▏                     | 127/399 [00:03<00:07, 34.50it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  33%|██████████▌                     | 131/399 [00:03<00:07, 35.38it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  33%|██████████▌                     | 131/399 [00:03<00:07, 35.38it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  33%|██████████▌                     | 131/399 [00:03<00:07, 35.38it/s, avg_loss=0.261, current_loss=0.263]\u001b[A\n",
      "Evaluating:  33%|██████████▌                     | 131/399 [00:03<00:07, 35.38it/s, avg_loss=0.261, current_loss=0.261]\u001b[A\n",
      "Evaluating:  33%|██████████▌                     | 131/399 [00:03<00:07, 35.38it/s, avg_loss=0.261, current_loss=0.263]\u001b[A\n",
      "Evaluating:  34%|██████████▊                     | 135/399 [00:03<00:08, 32.83it/s, avg_loss=0.261, current_loss=0.263]\u001b[A\n",
      "Evaluating:  34%|██████████▊                     | 135/399 [00:04<00:08, 32.83it/s, avg_loss=0.261, current_loss=0.263]\u001b[A\n",
      "Evaluating:  34%|██████████▊                     | 135/399 [00:04<00:08, 32.83it/s, avg_loss=0.261, current_loss=0.281]\u001b[A\n",
      "Evaluating:  34%|██████████▊                     | 135/399 [00:04<00:08, 32.83it/s, avg_loss=0.261, current_loss=0.257]\u001b[A\n",
      "Evaluating:  34%|██████████▊                     | 135/399 [00:04<00:08, 32.83it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  35%|███████████▏                    | 139/399 [00:04<00:07, 34.25it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  35%|███████████▏                    | 139/399 [00:04<00:07, 34.25it/s, avg_loss=0.261, current_loss=0.244]\u001b[A\n",
      "Evaluating:  35%|███████████▏                    | 139/399 [00:04<00:07, 34.25it/s, avg_loss=0.261, current_loss=0.262]\u001b[A\n",
      "Evaluating:  35%|███████████▏                    | 139/399 [00:04<00:07, 34.25it/s, avg_loss=0.261, current_loss=0.271]\u001b[A\n",
      "Evaluating:  35%|███████████▏                    | 139/399 [00:04<00:07, 34.25it/s, avg_loss=0.261, current_loss=0.256]\u001b[A\n",
      "Evaluating:  36%|███████████▍                    | 143/399 [00:04<00:07, 35.56it/s, avg_loss=0.261, current_loss=0.256]\u001b[A\n",
      "Evaluating:  36%|███████████▍                    | 143/399 [00:04<00:07, 35.56it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  36%|███████████▊                     | 143/399 [00:04<00:07, 35.56it/s, avg_loss=0.261, current_loss=0.25]\u001b[A\n",
      "Evaluating:  36%|███████████▍                    | 143/399 [00:04<00:07, 35.56it/s, avg_loss=0.261, current_loss=0.264]\u001b[A\n",
      "Evaluating:  36%|███████████▍                    | 143/399 [00:04<00:07, 35.56it/s, avg_loss=0.261, current_loss=0.271]\u001b[A\n",
      "Evaluating:  37%|███████████▊                    | 147/399 [00:04<00:07, 35.29it/s, avg_loss=0.261, current_loss=0.271]\u001b[A\n",
      "Evaluating:  37%|███████████▊                    | 147/399 [00:04<00:07, 35.29it/s, avg_loss=0.261, current_loss=0.265]\u001b[A\n",
      "Evaluating:  37%|███████████▊                    | 147/399 [00:04<00:07, 35.29it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  37%|███████████▊                    | 147/399 [00:04<00:07, 35.29it/s, avg_loss=0.261, current_loss=0.271]\u001b[A\n",
      "Evaluating:  37%|███████████▊                    | 147/399 [00:04<00:07, 35.29it/s, avg_loss=0.261, current_loss=0.261]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 151/399 [00:04<00:06, 35.98it/s, avg_loss=0.261, current_loss=0.261]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 151/399 [00:04<00:06, 35.98it/s, avg_loss=0.261, current_loss=0.246]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 151/399 [00:04<00:06, 35.98it/s, avg_loss=0.261, current_loss=0.273]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 151/399 [00:04<00:06, 35.98it/s, avg_loss=0.261, current_loss=0.246]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 151/399 [00:04<00:06, 35.98it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  39%|████████████▍                   | 155/399 [00:04<00:07, 32.79it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  39%|████████████▍                   | 155/399 [00:04<00:07, 32.79it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  39%|████████████▍                   | 155/399 [00:04<00:07, 32.79it/s, avg_loss=0.261, current_loss=0.258]\u001b[A\n",
      "Evaluating:  39%|████████████▍                   | 155/399 [00:04<00:07, 32.79it/s, avg_loss=0.261, current_loss=0.256]\u001b[A\n",
      "Evaluating:  39%|████████████▍                   | 155/399 [00:04<00:07, 32.79it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  40%|████████████▊                   | 159/399 [00:04<00:07, 34.21it/s, avg_loss=0.261, current_loss=0.266]\u001b[A\n",
      "Evaluating:  40%|█████████████▏                   | 159/399 [00:04<00:07, 34.21it/s, avg_loss=0.261, current_loss=0.27]\u001b[A\n",
      "Evaluating:  40%|████████████▊                   | 159/399 [00:04<00:07, 34.21it/s, avg_loss=0.261, current_loss=0.258]\u001b[A\n",
      "Evaluating:  40%|████████████▊                   | 159/399 [00:04<00:07, 34.21it/s, avg_loss=0.261, current_loss=0.263]\u001b[A\n",
      "Evaluating:  40%|████████████▊                   | 159/399 [00:04<00:07, 34.21it/s, avg_loss=0.261, current_loss=0.282]\u001b[A\n",
      "Evaluating:  41%|█████████████                   | 163/399 [00:04<00:06, 35.14it/s, avg_loss=0.261, current_loss=0.282]\u001b[A\n",
      "Evaluating:  41%|█████████████                   | 163/399 [00:04<00:06, 35.14it/s, avg_loss=0.261, current_loss=0.264]\u001b[A\n",
      "Evaluating:  41%|█████████████                   | 163/399 [00:04<00:06, 35.14it/s, avg_loss=0.261, current_loss=0.265]\u001b[A\n",
      "Evaluating:  41%|█████████████                   | 163/399 [00:04<00:06, 35.14it/s, avg_loss=0.261, current_loss=0.252]\u001b[A\n",
      "Evaluating:  41%|█████████████                   | 163/399 [00:04<00:06, 35.14it/s, avg_loss=0.261, current_loss=0.286]\u001b[A\n",
      "Evaluating:  41%|█████████████                   | 163/399 [00:04<00:06, 35.14it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  42%|█████████████▍                  | 168/399 [00:04<00:06, 36.33it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  42%|█████████████▍                  | 168/399 [00:04<00:06, 36.33it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  42%|█████████████▍                  | 168/399 [00:04<00:06, 36.33it/s, avg_loss=0.261, current_loss=0.265]\u001b[A\n",
      "Evaluating:  42%|█████████████▍                  | 168/399 [00:05<00:06, 36.33it/s, avg_loss=0.261, current_loss=0.262]\u001b[A\n",
      "Evaluating:  42%|█████████████▉                   | 168/399 [00:05<00:06, 36.33it/s, avg_loss=0.261, current_loss=0.27]\u001b[A\n",
      "Evaluating:  43%|██████████████▏                  | 172/399 [00:05<00:06, 34.02it/s, avg_loss=0.261, current_loss=0.27]\u001b[A\n",
      "Evaluating:  43%|█████████████▊                  | 172/399 [00:05<00:06, 34.02it/s, avg_loss=0.262, current_loss=0.272]\u001b[A\n",
      "Evaluating:  43%|█████████████▊                  | 172/399 [00:05<00:06, 34.02it/s, avg_loss=0.262, current_loss=0.266]\u001b[A\n",
      "Evaluating:  43%|█████████████▊                  | 172/399 [00:05<00:06, 34.02it/s, avg_loss=0.262, current_loss=0.253]\u001b[A\n",
      "Evaluating:  43%|██████████████▏                  | 172/399 [00:05<00:06, 34.02it/s, avg_loss=0.262, current_loss=0.27]\u001b[A\n",
      "Evaluating:  44%|██████████████▌                  | 176/399 [00:05<00:06, 35.01it/s, avg_loss=0.262, current_loss=0.27]\u001b[AException ignored in: <function tqdm.__del__ at 0x00000195AC9DBF60>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sebik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\sebik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py\", line 1277, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "       ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n",
      "\n",
      "Evaluating:  44%|██████████████                  | 176/399 [00:05<00:06, 35.01it/s, avg_loss=0.262, current_loss=0.262]\u001b[A\n",
      "Evaluating:  44%|██████████████                  | 176/399 [00:05<00:06, 35.01it/s, avg_loss=0.262, current_loss=0.256]\u001b[A\n",
      "Evaluating:  44%|██████████████                  | 176/399 [00:05<00:06, 35.01it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  44%|██████████████                  | 176/399 [00:05<00:06, 35.01it/s, avg_loss=0.262, current_loss=0.253]\u001b[A\n",
      "Evaluating:  45%|██████████████▍                 | 180/399 [00:05<00:09, 23.78it/s, avg_loss=0.262, current_loss=0.253]\u001b[A\n",
      "Evaluating:  45%|██████████████▍                 | 180/399 [00:05<00:09, 23.78it/s, avg_loss=0.262, current_loss=0.264]\u001b[A\n",
      "Evaluating:  45%|██████████████▍                 | 180/399 [00:05<00:09, 23.78it/s, avg_loss=0.262, current_loss=0.268]\u001b[A\n",
      "Evaluating:  45%|██████████████▍                 | 180/399 [00:05<00:09, 23.78it/s, avg_loss=0.261, current_loss=0.244]\u001b[A\n",
      "Evaluating:  45%|██████████████▍                 | 180/399 [00:05<00:09, 23.78it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  46%|██████████████▊                 | 184/399 [00:05<00:08, 24.92it/s, avg_loss=0.261, current_loss=0.251]\u001b[A\n",
      "Evaluating:  46%|██████████████▊                 | 184/399 [00:05<00:08, 24.92it/s, avg_loss=0.261, current_loss=0.265]\u001b[A\n",
      "Evaluating:  46%|██████████████▊                 | 184/399 [00:05<00:08, 24.92it/s, avg_loss=0.261, current_loss=0.253]\u001b[A\n",
      "Evaluating:  46%|██████████████▊                 | 184/399 [00:05<00:08, 24.92it/s, avg_loss=0.261, current_loss=0.244]\u001b[A\n",
      "Evaluating:  46%|██████████████▊                 | 184/399 [00:05<00:08, 24.92it/s, avg_loss=0.261, current_loss=0.259]\u001b[A\n",
      "Evaluating:  46%|███████████████▏                 | 184/399 [00:05<00:08, 24.92it/s, avg_loss=0.261, current_loss=0.26]\u001b[A\n",
      "Evaluating:  47%|███████████████▋                 | 189/399 [00:05<00:07, 29.52it/s, avg_loss=0.261, current_loss=0.26]\u001b[A\n",
      "Evaluating:  47%|███████████████▏                | 189/399 [00:05<00:07, 29.52it/s, avg_loss=0.261, current_loss=0.265]\u001b[A\n",
      "Evaluating:  47%|███████████████▏                | 189/399 [00:05<00:07, 29.52it/s, avg_loss=0.261, current_loss=0.282]\u001b[A\n",
      "Evaluating:  47%|███████████████▏                | 189/399 [00:05<00:07, 29.52it/s, avg_loss=0.262, current_loss=0.296]\u001b[A\n",
      "Evaluating:  47%|███████████████▏                | 189/399 [00:05<00:07, 29.52it/s, avg_loss=0.262, current_loss=0.264]\u001b[A\n",
      "Evaluating:  47%|███████████████▏                | 189/399 [00:05<00:07, 29.52it/s, avg_loss=0.262, current_loss=0.256]\u001b[A\n",
      "Evaluating:  49%|███████████████▌                | 194/399 [00:05<00:06, 32.94it/s, avg_loss=0.262, current_loss=0.256]\u001b[A\n",
      "Evaluating:  49%|███████████████▌                | 194/399 [00:05<00:06, 32.94it/s, avg_loss=0.262, current_loss=0.263]\u001b[A\n",
      "Evaluating:  49%|███████████████▌                | 194/399 [00:05<00:06, 32.94it/s, avg_loss=0.261, current_loss=0.241]\u001b[A\n",
      "Evaluating:  49%|███████████████▌                | 194/399 [00:05<00:06, 32.94it/s, avg_loss=0.261, current_loss=0.264]\u001b[A\n",
      "Evaluating:  49%|███████████████▌                | 194/399 [00:05<00:06, 32.94it/s, avg_loss=0.262, current_loss=0.275]\u001b[A\n",
      "Evaluating:  50%|███████████████▉                | 198/399 [00:05<00:05, 33.99it/s, avg_loss=0.262, current_loss=0.275]\u001b[A\n",
      "Evaluating:  50%|███████████████▉                | 198/399 [00:05<00:05, 33.99it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  50%|████████████████▍                | 198/399 [00:05<00:05, 33.99it/s, avg_loss=0.262, current_loss=0.27]\u001b[A\n",
      "Evaluating:  50%|███████████████▉                | 198/399 [00:06<00:05, 33.99it/s, avg_loss=0.262, current_loss=0.244]\u001b[A\n",
      "Evaluating:  50%|███████████████▉                | 198/399 [00:06<00:05, 33.99it/s, avg_loss=0.262, current_loss=0.285]\u001b[A\n",
      "Evaluating:  51%|████████████████▏               | 202/399 [00:06<00:05, 34.47it/s, avg_loss=0.262, current_loss=0.285]\u001b[A\n",
      "Evaluating:  51%|████████████████▏               | 202/399 [00:06<00:05, 34.47it/s, avg_loss=0.262, current_loss=0.277]\u001b[A\n",
      "Evaluating:  51%|████████████████▏               | 202/399 [00:06<00:05, 34.47it/s, avg_loss=0.262, current_loss=0.239]\u001b[A\n",
      "Evaluating:  51%|████████████████▏               | 202/399 [00:06<00:05, 34.47it/s, avg_loss=0.262, current_loss=0.273]\u001b[A\n",
      "Evaluating:  51%|████████████████▏               | 202/399 [00:06<00:05, 34.47it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  52%|████████████████▌               | 206/399 [00:06<00:05, 35.36it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  52%|████████████████▌               | 206/399 [00:06<00:05, 35.36it/s, avg_loss=0.262, current_loss=0.271]\u001b[A\n",
      "Evaluating:  52%|████████████████▌               | 206/399 [00:06<00:05, 35.36it/s, avg_loss=0.262, current_loss=0.284]\u001b[A\n",
      "Evaluating:  52%|████████████████▌               | 206/399 [00:06<00:05, 35.36it/s, avg_loss=0.262, current_loss=0.262]\u001b[A\n",
      "Evaluating:  52%|████████████████▌               | 206/399 [00:06<00:05, 35.36it/s, avg_loss=0.262, current_loss=0.264]\u001b[A\n",
      "Evaluating:  52%|████████████████▌               | 206/399 [00:06<00:05, 35.36it/s, avg_loss=0.262, current_loss=0.268]\u001b[A\n",
      "Evaluating:  53%|████████████████▉               | 211/399 [00:06<00:04, 37.72it/s, avg_loss=0.262, current_loss=0.268]\u001b[A\n",
      "Evaluating:  53%|████████████████▉               | 211/399 [00:06<00:04, 37.72it/s, avg_loss=0.262, current_loss=0.271]\u001b[A\n",
      "Evaluating:  53%|████████████████▉               | 211/399 [00:06<00:04, 37.72it/s, avg_loss=0.262, current_loss=0.249]\u001b[A\n",
      "Evaluating:  53%|████████████████▉               | 211/399 [00:06<00:04, 37.72it/s, avg_loss=0.262, current_loss=0.275]\u001b[A\n",
      "Evaluating:  53%|████████████████▉               | 211/399 [00:06<00:04, 37.72it/s, avg_loss=0.262, current_loss=0.259]\u001b[A\n",
      "Evaluating:  53%|████████████████▉               | 211/399 [00:06<00:04, 37.72it/s, avg_loss=0.262, current_loss=0.263]\u001b[A\n",
      "Evaluating:  54%|█████████████████▎              | 216/399 [00:06<00:04, 40.16it/s, avg_loss=0.262, current_loss=0.263]\u001b[A\n",
      "Evaluating:  54%|█████████████████▎              | 216/399 [00:06<00:04, 40.16it/s, avg_loss=0.262, current_loss=0.272]\u001b[A\n",
      "Evaluating:  54%|█████████████████▎              | 216/399 [00:06<00:04, 40.16it/s, avg_loss=0.262, current_loss=0.251]\u001b[A\n",
      "Evaluating:  54%|█████████████████▎              | 216/399 [00:06<00:04, 40.16it/s, avg_loss=0.262, current_loss=0.264]\u001b[A\n",
      "Evaluating:  54%|█████████████████▎              | 216/399 [00:06<00:04, 40.16it/s, avg_loss=0.262, current_loss=0.266]\u001b[A\n",
      "Evaluating:  54%|█████████████████▎              | 216/399 [00:06<00:04, 40.16it/s, avg_loss=0.262, current_loss=0.273]\u001b[A\n",
      "Evaluating:  55%|█████████████████▋              | 221/399 [00:06<00:04, 41.06it/s, avg_loss=0.262, current_loss=0.273]\u001b[A\n",
      "Evaluating:  55%|█████████████████▋              | 221/399 [00:06<00:04, 41.06it/s, avg_loss=0.262, current_loss=0.267]\u001b[A\n",
      "Evaluating:  55%|█████████████████▋              | 221/399 [00:06<00:04, 41.06it/s, avg_loss=0.262, current_loss=0.261]\u001b[A\n",
      "Evaluating:  55%|█████████████████▋              | 221/399 [00:06<00:04, 41.06it/s, avg_loss=0.262, current_loss=0.267]\u001b[A\n",
      "Evaluating:  55%|██████████████████▎              | 221/399 [00:06<00:04, 41.06it/s, avg_loss=0.262, current_loss=0.26]\u001b[A\n",
      "Evaluating:  55%|█████████████████▋              | 221/399 [00:06<00:04, 41.06it/s, avg_loss=0.262, current_loss=0.271]\u001b[A\n",
      "Evaluating:  57%|██████████████████▏             | 226/399 [00:06<00:04, 39.58it/s, avg_loss=0.262, current_loss=0.271]\u001b[A\n",
      "Evaluating:  57%|██████████████████▏             | 226/399 [00:06<00:04, 39.58it/s, avg_loss=0.262, current_loss=0.262]\u001b[A\n",
      "Evaluating:  57%|██████████████████▏             | 226/399 [00:06<00:04, 39.58it/s, avg_loss=0.262, current_loss=0.255]\u001b[A\n",
      "Evaluating:  57%|██████████████████▏             | 226/399 [00:06<00:04, 39.58it/s, avg_loss=0.262, current_loss=0.267]\u001b[A\n",
      "Evaluating:  57%|██████████████████▏             | 226/399 [00:06<00:04, 39.58it/s, avg_loss=0.262, current_loss=0.254]\u001b[A\n",
      "Evaluating:  57%|██████████████████▏             | 226/399 [00:06<00:04, 39.58it/s, avg_loss=0.262, current_loss=0.272]\u001b[A\n",
      "Evaluating:  58%|██████████████████▌             | 231/399 [00:06<00:04, 39.43it/s, avg_loss=0.262, current_loss=0.272]\u001b[A\n",
      "Evaluating:  58%|██████████████████▌             | 231/399 [00:06<00:04, 39.43it/s, avg_loss=0.262, current_loss=0.256]\u001b[A\n",
      "Evaluating:  58%|██████████████████▌             | 231/399 [00:06<00:04, 39.43it/s, avg_loss=0.262, current_loss=0.257]\u001b[A\n",
      "Evaluating:  58%|██████████████████▌             | 231/399 [00:06<00:04, 39.43it/s, avg_loss=0.262, current_loss=0.285]\u001b[A\n",
      "Evaluating:  58%|██████████████████▌             | 231/399 [00:06<00:04, 39.43it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  58%|██████████████████▌             | 231/399 [00:06<00:04, 39.43it/s, avg_loss=0.262, current_loss=0.273]\u001b[A\n",
      "Evaluating:  59%|██████████████████▉             | 236/399 [00:06<00:03, 41.10it/s, avg_loss=0.262, current_loss=0.273]\u001b[A\n",
      "Evaluating:  59%|██████████████████▉             | 236/399 [00:06<00:03, 41.10it/s, avg_loss=0.262, current_loss=0.278]\u001b[A\n",
      "Evaluating:  59%|███████████████████▌             | 236/399 [00:06<00:03, 41.10it/s, avg_loss=0.262, current_loss=0.25]\u001b[A\n",
      "Evaluating:  59%|██████████████████▉             | 236/399 [00:06<00:03, 41.10it/s, avg_loss=0.262, current_loss=0.272]\u001b[A\n",
      "Evaluating:  59%|██████████████████▉             | 236/399 [00:07<00:03, 41.10it/s, avg_loss=0.262, current_loss=0.258]\u001b[A\n",
      "Evaluating:  59%|███████████████████▌             | 236/399 [00:07<00:03, 41.10it/s, avg_loss=0.262, current_loss=0.28]\u001b[A\n",
      "Evaluating:  60%|███████████████████▉             | 241/399 [00:07<00:04, 36.18it/s, avg_loss=0.262, current_loss=0.28]\u001b[A\n",
      "Evaluating:  60%|███████████████████▎            | 241/399 [00:07<00:04, 36.18it/s, avg_loss=0.262, current_loss=0.243]\u001b[A\n",
      "Evaluating:  60%|███████████████████▎            | 241/399 [00:07<00:04, 36.18it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  60%|███████████████████▎            | 241/399 [00:07<00:04, 36.18it/s, avg_loss=0.262, current_loss=0.257]\u001b[A\n",
      "Evaluating:  60%|███████████████████▎            | 241/399 [00:07<00:04, 36.18it/s, avg_loss=0.262, current_loss=0.274]\u001b[A\n",
      "Evaluating:  61%|███████████████████▋            | 245/399 [00:07<00:04, 35.75it/s, avg_loss=0.262, current_loss=0.274]\u001b[A\n",
      "Evaluating:  61%|███████████████████▋            | 245/399 [00:07<00:04, 35.75it/s, avg_loss=0.262, current_loss=0.281]\u001b[A\n",
      "Evaluating:  61%|███████████████████▋            | 245/399 [00:07<00:04, 35.75it/s, avg_loss=0.262, current_loss=0.257]\u001b[A\n",
      "Evaluating:  61%|███████████████████▋            | 245/399 [00:07<00:04, 35.75it/s, avg_loss=0.262, current_loss=0.268]\u001b[A\n",
      "Evaluating:  61%|███████████████████▋            | 245/399 [00:07<00:04, 35.75it/s, avg_loss=0.262, current_loss=0.283]\u001b[A\n",
      "Evaluating:  62%|███████████████████▉            | 249/399 [00:07<00:04, 36.08it/s, avg_loss=0.262, current_loss=0.283]\u001b[A\n",
      "Evaluating:  62%|███████████████████▉            | 249/399 [00:07<00:04, 36.08it/s, avg_loss=0.262, current_loss=0.269]\u001b[A\n",
      "Evaluating:  62%|████████████████████▌            | 249/399 [00:07<00:04, 36.08it/s, avg_loss=0.262, current_loss=0.25]\u001b[A\n",
      "Evaluating:  62%|███████████████████▉            | 249/399 [00:07<00:04, 36.08it/s, avg_loss=0.262, current_loss=0.283]\u001b[A\n",
      "Evaluating:  62%|███████████████████▉            | 249/399 [00:07<00:04, 36.08it/s, avg_loss=0.262, current_loss=0.278]\u001b[A\n",
      "Evaluating:  63%|████████████████████▎           | 253/399 [00:07<00:03, 36.56it/s, avg_loss=0.262, current_loss=0.278]\u001b[A\n",
      "Evaluating:  63%|████████████████████▎           | 253/399 [00:07<00:03, 36.56it/s, avg_loss=0.263, current_loss=0.275]\u001b[A\n",
      "Evaluating:  63%|████████████████████▎           | 253/399 [00:07<00:03, 36.56it/s, avg_loss=0.263, current_loss=0.277]\u001b[A\n",
      "Evaluating:  63%|████████████████████▎           | 253/399 [00:07<00:03, 36.56it/s, avg_loss=0.263, current_loss=0.256]\u001b[A\n",
      "Evaluating:  63%|████████████████████▎           | 253/399 [00:07<00:03, 36.56it/s, avg_loss=0.263, current_loss=0.271]\u001b[A\n",
      "Evaluating:  64%|████████████████████▌           | 257/399 [00:07<00:03, 37.06it/s, avg_loss=0.263, current_loss=0.271]\u001b[A\n",
      "Evaluating:  64%|████████████████████▌           | 257/399 [00:07<00:03, 37.06it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  64%|████████████████████▌           | 257/399 [00:07<00:03, 37.06it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  64%|████████████████████▌           | 257/399 [00:07<00:03, 37.06it/s, avg_loss=0.263, current_loss=0.276]\u001b[A\n",
      "Evaluating:  64%|████████████████████▌           | 257/399 [00:07<00:03, 37.06it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  64%|████████████████████▌           | 257/399 [00:07<00:03, 37.06it/s, avg_loss=0.263, current_loss=0.284]\u001b[A\n",
      "Evaluating:  66%|█████████████████████           | 262/399 [00:07<00:03, 39.40it/s, avg_loss=0.263, current_loss=0.284]\u001b[A\n",
      "Evaluating:  66%|█████████████████████           | 262/399 [00:07<00:03, 39.40it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  66%|█████████████████████           | 262/399 [00:07<00:03, 39.40it/s, avg_loss=0.263, current_loss=0.291]\u001b[A\n",
      "Evaluating:  66%|█████████████████████           | 262/399 [00:07<00:03, 39.40it/s, avg_loss=0.263, current_loss=0.247]\u001b[A\n",
      "Evaluating:  66%|█████████████████████           | 262/399 [00:07<00:03, 39.40it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  67%|█████████████████████▎          | 266/399 [00:07<00:03, 36.23it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  67%|█████████████████████▎          | 266/399 [00:07<00:03, 36.23it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  67%|█████████████████████▎          | 266/399 [00:07<00:03, 36.23it/s, avg_loss=0.263, current_loss=0.264]\u001b[A\n",
      "Evaluating:  67%|█████████████████████▎          | 266/399 [00:07<00:03, 36.23it/s, avg_loss=0.263, current_loss=0.273]\u001b[A\n",
      "Evaluating:  67%|█████████████████████▎          | 266/399 [00:07<00:03, 36.23it/s, avg_loss=0.263, current_loss=0.257]\u001b[A\n",
      "Evaluating:  67%|█████████████████████▎          | 266/399 [00:07<00:03, 36.23it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  68%|█████████████████████▋          | 271/399 [00:07<00:03, 38.78it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  68%|█████████████████████▋          | 271/399 [00:07<00:03, 38.78it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  68%|█████████████████████▋          | 271/399 [00:07<00:03, 38.78it/s, avg_loss=0.263, current_loss=0.263]\u001b[A\n",
      "Evaluating:  68%|█████████████████████▋          | 271/399 [00:07<00:03, 38.78it/s, avg_loss=0.263, current_loss=0.266]\u001b[A\n",
      "Evaluating:  68%|█████████████████████▋          | 271/399 [00:07<00:03, 38.78it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  68%|█████████████████████▋          | 271/399 [00:07<00:03, 38.78it/s, avg_loss=0.263, current_loss=0.276]\u001b[A\n",
      "Evaluating:  69%|██████████████████████▏         | 276/399 [00:07<00:03, 40.77it/s, avg_loss=0.263, current_loss=0.276]\u001b[A\n",
      "Evaluating:  69%|██████████████████████▏         | 276/399 [00:07<00:03, 40.77it/s, avg_loss=0.263, current_loss=0.266]\u001b[A\n",
      "Evaluating:  69%|██████████████████████▏         | 276/399 [00:07<00:03, 40.77it/s, avg_loss=0.263, current_loss=0.249]\u001b[A\n",
      "Evaluating:  69%|██████████████████████▊          | 276/399 [00:07<00:03, 40.77it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  69%|██████████████████████▏         | 276/399 [00:08<00:03, 40.77it/s, avg_loss=0.263, current_loss=0.263]\u001b[A\n",
      "Evaluating:  69%|██████████████████████▏         | 276/399 [00:08<00:03, 40.77it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  70%|██████████████████████▌         | 281/399 [00:08<00:02, 41.96it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  70%|██████████████████████▌         | 281/399 [00:08<00:02, 41.96it/s, avg_loss=0.263, current_loss=0.262]\u001b[A\n",
      "Evaluating:  70%|██████████████████████▌         | 281/399 [00:08<00:02, 41.96it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:  70%|██████████████████████▌         | 281/399 [00:08<00:02, 41.96it/s, avg_loss=0.263, current_loss=0.261]\u001b[A\n",
      "Evaluating:  70%|██████████████████████▌         | 281/399 [00:08<00:02, 41.96it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:  70%|██████████████████████▌         | 281/399 [00:08<00:02, 41.96it/s, avg_loss=0.263, current_loss=0.284]\u001b[A\n",
      "Evaluating:  72%|██████████████████████▉         | 286/399 [00:08<00:02, 42.80it/s, avg_loss=0.263, current_loss=0.284]\u001b[A\n",
      "Evaluating:  72%|██████████████████████▉         | 286/399 [00:08<00:02, 42.80it/s, avg_loss=0.263, current_loss=0.248]\u001b[A\n",
      "Evaluating:  72%|██████████████████████▉         | 286/399 [00:08<00:02, 42.80it/s, avg_loss=0.263, current_loss=0.269]\u001b[A\n",
      "Evaluating:  72%|███████████████████████▋         | 286/399 [00:08<00:02, 42.80it/s, avg_loss=0.263, current_loss=0.25]\u001b[A\n",
      "Evaluating:  72%|██████████████████████▉         | 286/399 [00:08<00:02, 42.80it/s, avg_loss=0.263, current_loss=0.248]\u001b[A\n",
      "Evaluating:  72%|██████████████████████▉         | 286/399 [00:08<00:02, 42.80it/s, avg_loss=0.263, current_loss=0.273]\u001b[A\n",
      "Evaluating:  73%|███████████████████████▎        | 291/399 [00:08<00:02, 44.20it/s, avg_loss=0.263, current_loss=0.273]\u001b[A\n",
      "Evaluating:  73%|███████████████████████▎        | 291/399 [00:08<00:02, 44.20it/s, avg_loss=0.263, current_loss=0.256]\u001b[A\n",
      "Evaluating:  73%|███████████████████████▎        | 291/399 [00:08<00:02, 44.20it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  73%|███████████████████████▎        | 291/399 [00:08<00:02, 44.20it/s, avg_loss=0.263, current_loss=0.277]\u001b[A\n",
      "Evaluating:  73%|███████████████████████▎        | 291/399 [00:08<00:02, 44.20it/s, avg_loss=0.263, current_loss=0.261]\u001b[A\n",
      "Evaluating:  73%|████████████████████████         | 291/399 [00:08<00:02, 44.20it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  74%|████████████████████████▍        | 296/399 [00:08<00:02, 44.26it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  74%|███████████████████████▋        | 296/399 [00:08<00:02, 44.26it/s, avg_loss=0.263, current_loss=0.252]\u001b[A\n",
      "Evaluating:  74%|████████████████████████▍        | 296/399 [00:08<00:02, 44.26it/s, avg_loss=0.263, current_loss=0.25]\u001b[A\n",
      "Evaluating:  74%|███████████████████████▋        | 296/399 [00:08<00:02, 44.26it/s, avg_loss=0.263, current_loss=0.261]\u001b[A\n",
      "Evaluating:  74%|███████████████████████▋        | 296/399 [00:08<00:02, 44.26it/s, avg_loss=0.263, current_loss=0.268]\u001b[A\n",
      "Evaluating:  74%|███████████████████████▋        | 296/399 [00:08<00:02, 44.26it/s, avg_loss=0.263, current_loss=0.271]\u001b[A\n",
      "Evaluating:  75%|████████████████████████▏       | 301/399 [00:08<00:02, 42.94it/s, avg_loss=0.263, current_loss=0.271]\u001b[A\n",
      "Evaluating:  75%|████████████████████████▏       | 301/399 [00:08<00:02, 42.94it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:  75%|████████████████████████▏       | 301/399 [00:08<00:02, 42.94it/s, avg_loss=0.263, current_loss=0.247]\u001b[A\n",
      "Evaluating:  75%|████████████████████████▏       | 301/399 [00:08<00:02, 42.94it/s, avg_loss=0.263, current_loss=0.262]\u001b[A\n",
      "Evaluating:  75%|████████████████████████▏       | 301/399 [00:08<00:02, 42.94it/s, avg_loss=0.263, current_loss=0.287]\u001b[A\n",
      "Evaluating:  75%|████████████████████████▏       | 301/399 [00:08<00:02, 42.94it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  77%|████████████████████████▌       | 306/399 [00:08<00:02, 42.29it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  77%|████████████████████████▌       | 306/399 [00:08<00:02, 42.29it/s, avg_loss=0.263, current_loss=0.256]\u001b[A\n",
      "Evaluating:  77%|████████████████████████▌       | 306/399 [00:08<00:02, 42.29it/s, avg_loss=0.263, current_loss=0.262]\u001b[A\n",
      "Evaluating:  77%|████████████████████████▌       | 306/399 [00:08<00:02, 42.29it/s, avg_loss=0.263, current_loss=0.266]\u001b[A\n",
      "Evaluating:  77%|████████████████████████▌       | 306/399 [00:08<00:02, 42.29it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  77%|████████████████████████▌       | 306/399 [00:08<00:02, 42.29it/s, avg_loss=0.263, current_loss=0.277]\u001b[A\n",
      "Evaluating:  78%|████████████████████████▉       | 311/399 [00:08<00:02, 40.79it/s, avg_loss=0.263, current_loss=0.277]\u001b[A\n",
      "Evaluating:  78%|████████████████████████▉       | 311/399 [00:08<00:02, 40.79it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:  78%|████████████████████████▉       | 311/399 [00:08<00:02, 40.79it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:  78%|████████████████████████▉       | 311/399 [00:08<00:02, 40.79it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  78%|████████████████████████▉       | 311/399 [00:08<00:02, 40.79it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  78%|████████████████████████▉       | 311/399 [00:08<00:02, 40.79it/s, avg_loss=0.263, current_loss=0.241]\u001b[A\n",
      "Evaluating:  79%|█████████████████████████▎      | 316/399 [00:08<00:01, 41.60it/s, avg_loss=0.263, current_loss=0.241]\u001b[A\n",
      "Evaluating:  79%|█████████████████████████▎      | 316/399 [00:08<00:01, 41.60it/s, avg_loss=0.263, current_loss=0.257]\u001b[A\n",
      "Evaluating:  79%|█████████████████████████▎      | 316/399 [00:08<00:01, 41.60it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  79%|█████████████████████████▎      | 316/399 [00:08<00:01, 41.60it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  79%|█████████████████████████▎      | 316/399 [00:08<00:01, 41.60it/s, avg_loss=0.263, current_loss=0.259]\u001b[A\n",
      "Evaluating:  79%|█████████████████████████▎      | 316/399 [00:08<00:01, 41.60it/s, avg_loss=0.263, current_loss=0.262]\u001b[A\n",
      "Evaluating:  80%|█████████████████████████▋      | 321/399 [00:08<00:01, 40.10it/s, avg_loss=0.263, current_loss=0.262]\u001b[A\n",
      "Evaluating:  80%|█████████████████████████▋      | 321/399 [00:09<00:01, 40.10it/s, avg_loss=0.263, current_loss=0.268]\u001b[A\n",
      "Evaluating:  80%|██████████████████████████▌      | 321/399 [00:09<00:01, 40.10it/s, avg_loss=0.263, current_loss=0.25]\u001b[A\n",
      "Evaluating:  80%|█████████████████████████▋      | 321/399 [00:09<00:01, 40.10it/s, avg_loss=0.263, current_loss=0.249]\u001b[A\n",
      "Evaluating:  80%|█████████████████████████▋      | 321/399 [00:09<00:01, 40.10it/s, avg_loss=0.263, current_loss=0.284]\u001b[A\n",
      "Evaluating:  80%|█████████████████████████▋      | 321/399 [00:09<00:01, 40.10it/s, avg_loss=0.263, current_loss=0.246]\u001b[A\n",
      "Evaluating:  82%|██████████████████████████▏     | 326/399 [00:09<00:01, 40.96it/s, avg_loss=0.263, current_loss=0.246]\u001b[A\n",
      "Evaluating:  82%|██████████████████████████▏     | 326/399 [00:09<00:01, 40.96it/s, avg_loss=0.263, current_loss=0.249]\u001b[A\n",
      "Evaluating:  82%|██████████████████████████▏     | 326/399 [00:09<00:01, 40.96it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  82%|██████████████████████████▉      | 326/399 [00:09<00:01, 40.96it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  82%|██████████████████████████▏     | 326/399 [00:09<00:01, 40.96it/s, avg_loss=0.263, current_loss=0.269]\u001b[A\n",
      "Evaluating:  82%|██████████████████████████▏     | 326/399 [00:09<00:01, 40.96it/s, avg_loss=0.263, current_loss=0.283]\u001b[A\n",
      "Evaluating:  83%|██████████████████████████▌     | 331/399 [00:09<00:01, 41.20it/s, avg_loss=0.263, current_loss=0.283]\u001b[A\n",
      "Evaluating:  83%|██████████████████████████▌     | 331/399 [00:09<00:01, 41.20it/s, avg_loss=0.263, current_loss=0.266]\u001b[A\n",
      "Evaluating:  83%|██████████████████████████▌     | 331/399 [00:09<00:01, 41.20it/s, avg_loss=0.263, current_loss=0.254]\u001b[A\n",
      "Evaluating:  83%|██████████████████████████▌     | 331/399 [00:09<00:01, 41.20it/s, avg_loss=0.263, current_loss=0.252]\u001b[A\n",
      "Evaluating:  83%|██████████████████████████▌     | 331/399 [00:09<00:01, 41.20it/s, avg_loss=0.263, current_loss=0.259]\u001b[A\n",
      "Evaluating:  83%|██████████████████████████▌     | 331/399 [00:09<00:01, 41.20it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  84%|██████████████████████████▉     | 336/399 [00:09<00:01, 40.73it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  84%|██████████████████████████▉     | 336/399 [00:09<00:01, 40.73it/s, avg_loss=0.263, current_loss=0.261]\u001b[A\n",
      "Evaluating:  84%|███████████████████████████▊     | 336/399 [00:09<00:01, 40.73it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  84%|██████████████████████████▉     | 336/399 [00:09<00:01, 40.73it/s, avg_loss=0.263, current_loss=0.245]\u001b[A\n",
      "Evaluating:  84%|██████████████████████████▉     | 336/399 [00:09<00:01, 40.73it/s, avg_loss=0.263, current_loss=0.256]\u001b[A\n",
      "Evaluating:  84%|██████████████████████████▉     | 336/399 [00:09<00:01, 40.73it/s, avg_loss=0.263, current_loss=0.239]\u001b[A\n",
      "Evaluating:  85%|███████████████████████████▎    | 341/399 [00:09<00:01, 41.40it/s, avg_loss=0.263, current_loss=0.239]\u001b[A\n",
      "Evaluating:  85%|███████████████████████████▎    | 341/399 [00:09<00:01, 41.40it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  85%|███████████████████████████▎    | 341/399 [00:09<00:01, 41.40it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  85%|███████████████████████████▎    | 341/399 [00:09<00:01, 41.40it/s, avg_loss=0.263, current_loss=0.225]\u001b[A\n",
      "Evaluating:  85%|███████████████████████████▎    | 341/399 [00:09<00:01, 41.40it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  85%|████████████████████████████▏    | 341/399 [00:09<00:01, 41.40it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  87%|████████████████████████████▌    | 346/399 [00:09<00:01, 40.42it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  87%|███████████████████████████▋    | 346/399 [00:09<00:01, 40.42it/s, avg_loss=0.263, current_loss=0.274]\u001b[A\n",
      "Evaluating:  87%|███████████████████████████▋    | 346/399 [00:09<00:01, 40.42it/s, avg_loss=0.263, current_loss=0.263]\u001b[A\n",
      "Evaluating:  87%|███████████████████████████▋    | 346/399 [00:09<00:01, 40.42it/s, avg_loss=0.263, current_loss=0.267]\u001b[A\n",
      "Evaluating:  87%|████████████████████████████▌    | 346/399 [00:09<00:01, 40.42it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  87%|███████████████████████████▋    | 346/399 [00:09<00:01, 40.42it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████▏   | 351/399 [00:09<00:01, 35.93it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████▏   | 351/399 [00:09<00:01, 35.93it/s, avg_loss=0.263, current_loss=0.282]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████▏   | 351/399 [00:09<00:01, 35.93it/s, avg_loss=0.263, current_loss=0.248]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████▏   | 351/399 [00:09<00:01, 35.93it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████▏   | 351/399 [00:09<00:01, 35.93it/s, avg_loss=0.263, current_loss=0.254]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████▏   | 351/399 [00:09<00:01, 35.93it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  89%|████████████████████████████▌   | 356/399 [00:09<00:01, 38.23it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  89%|████████████████████████████▌   | 356/399 [00:09<00:01, 38.23it/s, avg_loss=0.263, current_loss=0.268]\u001b[A\n",
      "Evaluating:  89%|████████████████████████████▌   | 356/399 [00:09<00:01, 38.23it/s, avg_loss=0.263, current_loss=0.258]\u001b[A\n",
      "Evaluating:  89%|█████████████████████████████▍   | 356/399 [00:10<00:01, 38.23it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  89%|████████████████████████████▌   | 356/399 [00:10<00:01, 38.23it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:  90%|████████████████████████████▊   | 360/399 [00:10<00:01, 34.71it/s, avg_loss=0.263, current_loss=0.253]\u001b[A\n",
      "Evaluating:  90%|████████████████████████████▊   | 360/399 [00:10<00:01, 34.71it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:  90%|████████████████████████████▊   | 360/399 [00:10<00:01, 34.71it/s, avg_loss=0.263, current_loss=0.273]\u001b[A\n",
      "Evaluating:  90%|████████████████████████████▊   | 360/399 [00:10<00:01, 34.71it/s, avg_loss=0.263, current_loss=0.264]\u001b[A\n",
      "Evaluating:  90%|████████████████████████████▊   | 360/399 [00:10<00:01, 34.71it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  91%|█████████████████████████████▏  | 364/399 [00:10<00:01, 34.24it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  91%|█████████████████████████████▏  | 364/399 [00:10<00:01, 34.24it/s, avg_loss=0.263, current_loss=0.259]\u001b[A\n",
      "Evaluating:  91%|█████████████████████████████▏  | 364/399 [00:10<00:01, 34.24it/s, avg_loss=0.263, current_loss=0.277]\u001b[A\n",
      "Evaluating:  91%|█████████████████████████████▏  | 364/399 [00:10<00:01, 34.24it/s, avg_loss=0.263, current_loss=0.249]\u001b[A\n",
      "Evaluating:  91%|██████████████████████████████   | 364/399 [00:10<00:01, 34.24it/s, avg_loss=0.263, current_loss=0.25]\u001b[A\n",
      "Evaluating:  91%|█████████████████████████████▏  | 364/399 [00:10<00:01, 34.24it/s, avg_loss=0.263, current_loss=0.257]\u001b[A\n",
      "Evaluating:  92%|█████████████████████████████▌  | 369/399 [00:10<00:00, 36.61it/s, avg_loss=0.263, current_loss=0.257]\u001b[A\n",
      "Evaluating:  92%|█████████████████████████████▌  | 369/399 [00:10<00:00, 36.61it/s, avg_loss=0.263, current_loss=0.272]\u001b[A\n",
      "Evaluating:  92%|█████████████████████████████▌  | 369/399 [00:10<00:00, 36.61it/s, avg_loss=0.263, current_loss=0.266]\u001b[A\n",
      "Evaluating:  92%|█████████████████████████████▌  | 369/399 [00:10<00:00, 36.61it/s, avg_loss=0.263, current_loss=0.249]\u001b[A\n",
      "Evaluating:  92%|██████████████████████████████▌  | 369/399 [00:10<00:00, 36.61it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  92%|█████████████████████████████▌  | 369/399 [00:10<00:00, 36.61it/s, avg_loss=0.263, current_loss=0.242]\u001b[A\n",
      "Evaluating:  94%|█████████████████████████████▉  | 374/399 [00:10<00:00, 38.48it/s, avg_loss=0.263, current_loss=0.242]\u001b[A\n",
      "Evaluating:  94%|█████████████████████████████▉  | 374/399 [00:10<00:00, 38.48it/s, avg_loss=0.263, current_loss=0.254]\u001b[A\n",
      "Evaluating:  94%|█████████████████████████████▉  | 374/399 [00:10<00:00, 38.48it/s, avg_loss=0.263, current_loss=0.284]\u001b[A\n",
      "Evaluating:  94%|█████████████████████████████▉  | 374/399 [00:10<00:00, 38.48it/s, avg_loss=0.263, current_loss=0.276]\u001b[A\n",
      "Evaluating:  94%|██████████████████████████████▉  | 374/399 [00:10<00:00, 38.48it/s, avg_loss=0.263, current_loss=0.24]\u001b[A\n",
      "Evaluating:  95%|███████████████████████████████▎ | 378/399 [00:10<00:00, 37.36it/s, avg_loss=0.263, current_loss=0.24]\u001b[A\n",
      "Evaluating:  95%|██████████████████████████████▎ | 378/399 [00:10<00:00, 37.36it/s, avg_loss=0.263, current_loss=0.245]\u001b[A\n",
      "Evaluating:  95%|██████████████████████████████▎ | 378/399 [00:10<00:00, 37.36it/s, avg_loss=0.262, current_loss=0.262]\u001b[A\n",
      "Evaluating:  95%|██████████████████████████████▎ | 378/399 [00:10<00:00, 37.36it/s, avg_loss=0.263, current_loss=0.276]\u001b[A\n",
      "Evaluating:  95%|██████████████████████████████▎ | 378/399 [00:10<00:00, 37.36it/s, avg_loss=0.263, current_loss=0.266]\u001b[A\n",
      "Evaluating:  95%|██████████████████████████████▎ | 378/399 [00:10<00:00, 37.36it/s, avg_loss=0.263, current_loss=0.268]\u001b[A\n",
      "Evaluating:  96%|██████████████████████████████▋ | 383/399 [00:10<00:00, 38.73it/s, avg_loss=0.263, current_loss=0.268]\u001b[A\n",
      "Evaluating:  96%|███████████████████████████████▋ | 383/399 [00:10<00:00, 38.73it/s, avg_loss=0.263, current_loss=0.26]\u001b[A\n",
      "Evaluating:  96%|██████████████████████████████▋ | 383/399 [00:10<00:00, 38.73it/s, avg_loss=0.263, current_loss=0.265]\u001b[A\n",
      "Evaluating:  96%|██████████████████████████████▋ | 383/399 [00:10<00:00, 38.73it/s, avg_loss=0.263, current_loss=0.278]\u001b[A\n",
      "Evaluating:  96%|██████████████████████████████▋ | 383/399 [00:10<00:00, 38.73it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  97%|███████████████████████████████ | 387/399 [00:10<00:00, 38.86it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  97%|███████████████████████████████ | 387/399 [00:10<00:00, 38.86it/s, avg_loss=0.263, current_loss=0.255]\u001b[A\n",
      "Evaluating:  97%|███████████████████████████████ | 387/399 [00:10<00:00, 38.86it/s, avg_loss=0.263, current_loss=0.243]\u001b[A\n",
      "Evaluating:  97%|████████████████████████████████ | 387/399 [00:10<00:00, 38.86it/s, avg_loss=0.263, current_loss=0.27]\u001b[A\n",
      "Evaluating:  97%|███████████████████████████████ | 387/399 [00:10<00:00, 38.86it/s, avg_loss=0.262, current_loss=0.251]\u001b[A\n",
      "Evaluating:  98%|███████████████████████████████▎| 391/399 [00:10<00:00, 38.81it/s, avg_loss=0.262, current_loss=0.251]\u001b[A\n",
      "Evaluating:  98%|███████████████████████████████▎| 391/399 [00:10<00:00, 38.81it/s, avg_loss=0.262, current_loss=0.263]\u001b[A\n",
      "Evaluating:  98%|███████████████████████████████▎| 391/399 [00:10<00:00, 38.81it/s, avg_loss=0.262, current_loss=0.239]\u001b[A\n",
      "Evaluating:  98%|████████████████████████████████▎| 391/399 [00:10<00:00, 38.81it/s, avg_loss=0.262, current_loss=0.24]\u001b[A\n",
      "Evaluating:  98%|███████████████████████████████▎| 391/399 [00:10<00:00, 38.81it/s, avg_loss=0.262, current_loss=0.265]\u001b[A\n",
      "Evaluating:  98%|███████████████████████████████▎| 391/399 [00:10<00:00, 38.81it/s, avg_loss=0.262, current_loss=0.257]\u001b[A\n",
      "Evaluating:  99%|███████████████████████████████▊| 396/399 [00:10<00:00, 37.54it/s, avg_loss=0.262, current_loss=0.257]\u001b[A\n",
      "Evaluating:  99%|███████████████████████████████▊| 396/399 [00:11<00:00, 37.54it/s, avg_loss=0.262, current_loss=0.234]\u001b[A\n",
      "Evaluating:  99%|███████████████████████████████▊| 396/399 [00:11<00:00, 37.54it/s, avg_loss=0.262, current_loss=0.249]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 399/399 [00:11<00:00, 36.11it/s, avg_loss=0.262, current_loss=0.208]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating - Average Loss: 0.26226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Models import *\n",
    "eval_model(Stationary_Model().to(device), dataloader) # 0.00262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86f21820-ce37-4689-9288-de902b18f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0177,  0.0076,  0.0145],\n",
      "         [ 0.0380, -0.0054, -0.0150],\n",
      "         [ 0.0084, -0.0430, -0.0192],\n",
      "         ...,\n",
      "         [ 0.0533, -0.0061, -0.0016],\n",
      "         [ 0.0430, -0.0043,  0.0008],\n",
      "         [-0.0049,  0.0170,  0.0106]],\n",
      "\n",
      "        [[ 0.0305, -0.0143,  0.0384],\n",
      "         [ 0.0234, -0.0359,  0.0153],\n",
      "         [ 0.0332, -0.0174,  0.0114],\n",
      "         ...,\n",
      "         [ 0.0533, -0.0061, -0.0016],\n",
      "         [ 0.0430, -0.0043,  0.0008],\n",
      "         [-0.0049,  0.0170,  0.0106]],\n",
      "\n",
      "        [[ 0.0356, -0.0230,  0.0304],\n",
      "         [ 0.0521, -0.0095,  0.0244],\n",
      "         [ 0.0305, -0.0032, -0.0018],\n",
      "         ...,\n",
      "         [ 0.0533, -0.0061, -0.0016],\n",
      "         [ 0.0430, -0.0043,  0.0008],\n",
      "         [-0.0049,  0.0170,  0.0106]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0338, -0.0177, -0.0106],\n",
      "         [ 0.0272,  0.0040,  0.0302],\n",
      "         [ 0.0475,  0.0062,  0.0303],\n",
      "         ...,\n",
      "         [ 0.0533, -0.0061, -0.0016],\n",
      "         [ 0.0430, -0.0043,  0.0008],\n",
      "         [-0.0049,  0.0170,  0.0106]],\n",
      "\n",
      "        [[ 0.0533, -0.0238,  0.0017],\n",
      "         [ 0.0511, -0.0162, -0.0010],\n",
      "         [ 0.0321, -0.0002,  0.0148],\n",
      "         ...,\n",
      "         [ 0.0533, -0.0061, -0.0016],\n",
      "         [ 0.0430, -0.0043,  0.0008],\n",
      "         [-0.0049,  0.0170,  0.0106]],\n",
      "\n",
      "        [[ 0.0127,  0.0006,  0.0649],\n",
      "         [ 0.0086, -0.0039,  0.0346],\n",
      "         [-0.0048, -0.0181,  0.0152],\n",
      "         ...,\n",
      "         [ 0.0533, -0.0061, -0.0016],\n",
      "         [ 0.0430, -0.0043,  0.0008],\n",
      "         [-0.0049,  0.0170,  0.0106]]], device='cuda:0',\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for currents, deltas, lengths in dataloader:\n",
    "        \n",
    "    # Move data to device\n",
    "    currents = currents.to(device)\n",
    "    deltas = deltas.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    \n",
    "    # Forward pass: predict deltas using currents.\n",
    "    pred_deltas = model(currents)\n",
    "    print(pred_deltas)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a88f1537-259d-4ac4-bf58-637a42c178be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 11:50:37,903] A new study created in memory with name: no-name-663c8c93-9cfe-470a-a551-431c4a0c6214\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 55.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 57.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 56.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 58.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 54.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 53.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:13<00:00, 49.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:03<00:00, 47.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:13<00:00, 46.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 65.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 56.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 60.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:10<00:00, 59.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 60.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 58.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 63.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 54.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 53.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 54.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 61.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 57.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 62.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:10<00:00, 59.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 62.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:10<00:00, 58.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 62.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 55.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 61.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:10<00:00, 59.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 60.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 55.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 55.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 640/640 [00:11<00:00, 57.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:02<00:00, 61.82it/s]\n",
      " 48%|██████████████████████████████████████▊                                         | 310/640 [00:05<00:05, 57.29it/s]\n",
      "[W 2025-04-25 11:54:44,621] Trial 0 failed with parameters: {'lr': 0.0001505499224340741, 'weight_decay': 0.002960184249542081, 'optimizer': 'SGD', 'batch_size': 128, 'channels_1': 64, 'channels_2': 128, 'kernel_size_1': 1, 'kernel_size_2': 7, 'kernel_size_3': 1, 'coordinate_factor': 0.4724671401878715} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sebik\\.conda\\envs\\thesis\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\sebik\\AppData\\Local\\Temp\\ipykernel_120400\\4247618629.py\", line 52, in cnn_objective\n",
      "    optimizer.step()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\sebik\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 485, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sebik\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 79, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\sebik\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 125, in step\n",
      "    sgd(\n",
      "    ~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<12 lines>...\n",
      "        found_inf=getattr(self, \"found_inf\", None),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\sebik\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 300, in sgd\n",
      "    func(\n",
      "    ~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<10 lines>...\n",
      "        found_inf=found_inf,\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\sebik\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\sgd.py\", line 415, in _multi_tensor_sgd\n",
      "    device_grads = torch._foreach_add(  # type: ignore[assignment]\n",
      "        device_grads, device_params, alpha=weight_decay\n",
      "    )\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-25 11:54:44,628] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(\n\u001b[32m      2\u001b[39m         direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m         pruner=optuna.pruners.MedianPruner(n_startup_trials=\u001b[32m5\u001b[39m, n_warmup_steps=\u001b[32m2\u001b[39m)\n\u001b[32m      4\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mcnn_objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     50\u001b[39m     loss = masked_mse_loss(pred_deltas, deltas, lengths)\n\u001b[32m     51\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Intermediate evaluation\u001b[39;00m\n\u001b[32m     55\u001b[39m running_loss = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\sgd.py:125\u001b[39m, in \u001b[36mSGD.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    119\u001b[39m momentum_buffer_list: \u001b[38;5;28mlist\u001b[39m[Optional[Tensor]] = []\n\u001b[32m    121\u001b[39m has_sparse_grad = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    122\u001b[39m     group, params, grads, momentum_buffer_list\n\u001b[32m    123\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmomentum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdampening\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnesterov\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[33m\"\u001b[39m\u001b[33mmomentum\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[32m0\u001b[39m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\sgd.py:300\u001b[39m, in \u001b[36msgd\u001b[39m\u001b[34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    298\u001b[39m     func = _single_tensor_sgd\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\thesis\\Lib\\site-packages\\torch\\optim\\sgd.py:415\u001b[39m, in \u001b[36m_multi_tensor_sgd\u001b[39m\u001b[34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[39m\n\u001b[32m    413\u001b[39m         torch._foreach_add_(device_grads, device_params, alpha=weight_decay)\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m         device_grads = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m momentum != \u001b[32m0\u001b[39m:\n\u001b[32m    420\u001b[39m     bufs: \u001b[38;5;28mlist\u001b[39m[Tensor] = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=2)\n",
    "    )\n",
    "study.optimize(cnn_objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540332f-34b3-40eb-84aa-09afc5a5ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
